{
    "model": "NGPT",
    
    "dataset_path": "../datasets/pretrain/dataset.json",
    "tokenizer_path": "tokenizers/tokenizer32k",
    "max_length": 1024,
    "model_dim": 1024,
    "num_heads": 16,
    "num_layers": 20,
    "dropout": 0.1,
    "batch_size": 1,
    "val_batch_size": 4,
    "n_batches_per_step": 256,
    "max_learning_rate": 2e-3,
    "min_learning_rate": 1e-6,
    "warmup_steps": 0,
    "total_steps": 20000,
    "validation_interval": 50,

    "top_p": 0.1,
    "temperature": 0.5,

    "model_path": "transformers/ngpt/pretrain0.4b",
    "checkpoint_step": 20000,

    "log_file": "pretrain.log"
}